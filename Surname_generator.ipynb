{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Russian surname generator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhurbey/Surname_Generator/blob/master/Surname_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "1Aned9yfQrd2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BqxJ0hLO4jvf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#upload the data\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YGDPHxzQF4CO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.test.is_gpu_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mCO3z_CeP4i7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#creating alphabet\n",
        "first_letter = ord('а')\n",
        "last_letter = ord('я')\n",
        "alphabet = []\n",
        "for letter in range(first_letter,last_letter+1):\n",
        "    alphabet.append(chr(letter))\n",
        "    \n",
        "#inserting extra symbols\n",
        "alphabet.insert(6, \"ё\")\n",
        "#inserting on empty space in order to be able to read shorter output\n",
        "alphabet.insert(0, \" \")\n",
        "alphabet.insert(34,\"-\")\n",
        "alphabet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lUAHpGMHQJ7w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#checking the lenth of the alphabet\n",
        "len(alphabet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QL82dBViLyz1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#encoding a word function\n",
        "def encode_word(word):\n",
        "  #Downcase the word\n",
        "  word = word.lower()\n",
        "  x = 0\n",
        "  encoded_word = []\n",
        "  while x < 15:\n",
        "    lenth = len(word)\n",
        "    # add empty spaces to shorter words so imput is always 15 nodes\n",
        "    if lenth < 15:\n",
        "      difference = 15 - lenth\n",
        "      while difference > 0:\n",
        "        longer_word = word + \" \"\n",
        "        word = longer_word\n",
        "        difference = difference - 1\n",
        "    # find index of a letter from the word    \n",
        "    letter_index = alphabet.index(word[x])\n",
        "    # add indeces to the list\n",
        "    encoded_word.append(letter_index)\n",
        "    x+=1\n",
        "  return encoded_word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fbTLkFzKcfo1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#normalizing encoded word function\n",
        "def normalize_by(encoded_word):\n",
        "  # normalised [0,1]\n",
        "  normalized_word = (encoded_word - np.min([0]))/np.ptp([0,len(alphabet)])\n",
        "  return normalized_word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DbXt67ne5Aub",
        "colab_type": "code",
        "outputId": "b2313969-aedd-4b87-d70e-ff8751b43dd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "#data to pandas DataFrame\n",
        "\n",
        "df = pd.read_excel(\"Russian_Surname_250K.xlsx\")\n",
        "df.head()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SURNAMES</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ААЛФЕРОВА</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ААЛЬ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ААМАН</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ААМАНА</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ААМАНАЯ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    SURNAMES\n",
              "0  ААЛФЕРОВА\n",
              "1       ААЛЬ\n",
              "2      ААМАН\n",
              "3     ААМАНА\n",
              "4    ААМАНАЯ"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "wqXE0qPQYWjO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2eb720da-5bb3-417d-ee1f-50e71ba6bc53"
      },
      "cell_type": "code",
      "source": [
        "#For better perfomance we leave only surnames that are 8 letters long and end with \"ОВ\"(optional)\n",
        "df['SURNAMES'] = df['SURNAMES'].astype('str')\n",
        "mask = (df['SURNAMES'].str.len() == 8) & (df['SURNAMES'].str.endswith(\"ОВ\"))\n",
        "df.head()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SURNAMES</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>АБАБИЛОВ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>АБАКАРОВ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>АБАКУЛОВ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>АБАКУМОВ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>АБАЛАКОВ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    SURNAMES\n",
              "13  АБАБИЛОВ\n",
              "57  АБАКАРОВ\n",
              "69  АБАКУЛОВ\n",
              "73  АБАКУМОВ\n",
              "88  АБАЛАКОВ"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "metadata": {
        "id": "KOBMzPhaY1_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "4c0ead09-92ab-416a-a7d7-3cae438bbf77"
      },
      "cell_type": "code",
      "source": [
        "#while encoding encoder found there is a surname in data that has '\\x1b' as a aprt of it, so this code is to remove that surname\n",
        "#df[df['SURNAMES'].str.contains('\\x1b')]\n",
        "#df = df.drop(axis=0,index = 105298)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SURNAMES</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>105298</th>\n",
              "      <td>КРАС\u001bНОВ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        SURNAMES\n",
              "105298  КРАС\u001bНОВ"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "metadata": {
        "id": "TJhV3HnJhibs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df65113c-877c-4a8b-ab2e-93c9fb598869"
      },
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9158, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "metadata": {
        "id": "fJDzIywg462b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#encode and normalize data\n",
        "encoded_normalized_data = []\n",
        "for word in df[\"SURNAMES\"]:\n",
        "  encoded_word = encode_word(word)\n",
        "  normalized_word = normalize_by(encoded_word)\n",
        "  encoded_normalized_data.append(normalized_word)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GfTtB4QtBhR2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IFTZf7_f97i3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#creating generator function\n",
        "def generator(z,reuse=None):\n",
        "    with tf.variable_scope('gen',reuse=reuse):\n",
        "        hidden1 = tf.layers.dense(inputs=z,units=128)\n",
        "        # Leaky Relu\n",
        "        alpha = 0.01\n",
        "        hidden1 = tf.maximum(alpha*hidden1,hidden1)\n",
        "        hidden2 = tf.layers.dense(inputs=hidden1,units=128)\n",
        "        \n",
        "        hidden2 = tf.maximum(alpha*hidden2,hidden2)\n",
        "        output = tf.layers.dense(hidden2,units=15,activation=tf.nn.tanh)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HOrEeZEz-CIm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#creating descriminator function\n",
        "def discriminator(X,reuse=None):\n",
        "    with tf.variable_scope('dis',reuse=reuse):\n",
        "        hidden1 = tf.layers.dense(inputs=X,units=128)\n",
        "        # Leaky Relu\n",
        "        alpha = 0.01\n",
        "        hidden1 = tf.maximum(alpha*hidden1,hidden1)\n",
        "        \n",
        "        hidden2 = tf.layers.dense(inputs=hidden1,units=128)\n",
        "        hidden2 = tf.maximum(alpha*hidden2,hidden2)\n",
        "        \n",
        "        logits = tf.layers.dense(hidden2,units=1)\n",
        "        output = tf.sigmoid(logits)\n",
        "    \n",
        "        return output, logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tsj6pj_o-ecF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Creating placeholders\n",
        "real_words = tf.placeholder(tf.float32,shape=[None,15])\n",
        "z = tf.placeholder(tf.float32,shape=[None,15])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "whT8efKA-zn1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Creating generator\n",
        "G = generator(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aiLogVTYCETy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Creating discriminators\n",
        "D_output_real , D_logits_real = discriminator(real_words)\n",
        "D_output_fake, D_logits_fake = discriminator(G,reuse=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9FPISlW_CNkD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Loss function\n",
        "def loss_func(logits_in,labels_in):\n",
        "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_in,labels=labels_in))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2NVDFTLBCYmY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Losses\n",
        "D_real_loss = loss_func(D_logits_real,tf.ones_like(D_logits_real)* (0.9))\n",
        "\n",
        "D_fake_loss = loss_func(D_logits_fake,tf.zeros_like(D_logits_real))\n",
        "\n",
        "D_loss = D_real_loss + D_fake_loss\n",
        "\n",
        "G_loss = loss_func(D_logits_fake,tf.ones_like(D_logits_fake))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SqwRQnrgCl-_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x6-Xdl4ZCpGQ",
        "colab_type": "code",
        "outputId": "6e3d383b-a3c5-42b4-bf29-81625b4a039d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Group variables\n",
        "tvars = tf.trainable_variables()\n",
        "\n",
        "d_vars = [var for var in tvars if 'dis' in var.name]\n",
        "g_vars = [var for var in tvars if 'gen' in var.name]\n",
        "\n",
        "print([v.name for v in d_vars])\n",
        "print([v.name for v in g_vars])"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['dis/dense/kernel:0', 'dis/dense/bias:0', 'dis/dense_1/kernel:0', 'dis/dense_1/bias:0', 'dis/dense_2/kernel:0', 'dis/dense_2/bias:0']\n",
            "['gen/dense/kernel:0', 'gen/dense/bias:0', 'gen/dense_1/kernel:0', 'gen/dense_1/bias:0', 'gen/dense_2/kernel:0', 'gen/dense_2/bias:0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K5aVLYBpFKSN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Creating trainers\n",
        "D_trainer = tf.train.AdamOptimizer(learning_rate).minimize(D_loss, var_list=d_vars)\n",
        "G_trainer = tf.train.AdamOptimizer(learning_rate).minimize(G_loss, var_list=g_vars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x-DNXDH5CsLn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Batch size and number of epochs\n",
        "batch_size = 60\n",
        "epochs = 500\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver(var_list=g_vars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jAFI6-_HAwpX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Next batch function\n",
        "def next_batch(num, data):\n",
        "    '''\n",
        "    Return a total of `num` random samples and labels. \n",
        "    '''\n",
        "    idx = np.arange(0 , len(data))\n",
        "    np.random.shuffle(idx)\n",
        "    idx = idx[:num]\n",
        "    data_shuffle = [data[ i] for i in idx]\n",
        " \n",
        "    #labels_shuffle = [labels[ i] for i in idx]\n",
        "\n",
        "    return np.asarray(data_shuffle) #np.asarray(labels_shuffle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RI7bCA2QC31k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save a sample per epoch\n",
        "samples = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "32bBSBiMC58N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    \n",
        "    sess.run(init)\n",
        "    \n",
        "    # Recall an epoch is an entire run through the training data\n",
        "    for e in range(epochs):\n",
        "        # // indicates classic division\n",
        "        num_batches = len(newdf[\"SURNAMES\"]) // batch_size\n",
        "        \n",
        "        for i in range(num_batches):\n",
        "            \n",
        "            # Grab batch of words\n",
        "            batch = next_batch(batch_size, encoded_normalized_data)\n",
        "            \n",
        "            # Get words, reshape and rescale to pass to D\n",
        "            batch_words = batch.reshape((batch_size, 15))\n",
        "            \n",
        "            \n",
        "            \n",
        "            # Z (random latent noise data for Generator)\n",
        "            # -1 to 1 because of tanh activation\n",
        "            batch_z = np.random.uniform(-1, 1, size=(batch_size, 15))\n",
        "            \n",
        "            # Run optimizers, no need to save outputs, we won't use them\n",
        "            _ = sess.run(D_trainer, feed_dict={real_words: batch_words, z: batch_z})\n",
        "            _ = sess.run(G_trainer, feed_dict={z: batch_z})\n",
        "        \n",
        "            \n",
        "        print(\"Currently on Epoch {} of {} total...\".format(e+1, epochs))\n",
        "        \n",
        "        # Sample from generator as we're training for viewing afterwards\n",
        "        sample_z = np.random.uniform(-1, 1, size=(1, 15))\n",
        "        gen_sample = sess.run(generator(z ,reuse=True),feed_dict={z: sample_z})\n",
        "        \n",
        "        samples.append(gen_sample)\n",
        "        \n",
        "#         saver.save(sess, './models/500_epoch_model.ckpt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1idjZohtGI25",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#denormalize function\n",
        "def denormalize_by(encoded_word):\n",
        "  \n",
        "  normalized_word = (encoded_word - np.min([0]))*np.ptp([0,len(alphabet)])\n",
        "  return normalized_word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RGQnUTRVG_Ld",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#decode words function\n",
        "def decode_words(output_words):\n",
        "  decoded_words = []\n",
        "  for word in output_words:\n",
        "    \n",
        "    decoded_word = []\n",
        "\n",
        "    for x in word:\n",
        "      x = np.round(x)\n",
        "      \n",
        "    decoded_word = x\n",
        "    decoded_word = decoded_word.astype(int)\n",
        "    decoded_word_string = \"\"\n",
        "    a = 0\n",
        "    \n",
        "    while a < 15:\n",
        "      \n",
        "      b = decoded_word[a]\n",
        "      \n",
        "      if b < 0 or b > (len(alphabet)-1):\n",
        "        b = 0\n",
        "      b = alphabet[b]\n",
        "      \n",
        "      decoded_word_string = decoded_word_string + b\n",
        "\n",
        "      a+=1\n",
        "\n",
        "    decoded_words.append(decoded_word_string)\n",
        "\n",
        "\n",
        "  return decoded_words\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E8BAEv3jdQsV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#denormalize Output\n",
        "denorm_words = []\n",
        "for word in samples:\n",
        "  denormword = denormalize_by(word)\n",
        "  denorm_words.append(denormword)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mYYdQOyGSXjX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Decode denormalized output\n",
        "decoded_words = decode_words(denorm_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y1SkfnuLPA7B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#See the result\n",
        "decoded_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-tLK1VxohOLu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Save to Excel file and download\n",
        "comletewords = pd.DataFrame(decoded_words)\n",
        "file_name = 'OutputSurnames.xlsx'\n",
        "writer = pd.ExcelWriter(file_name)\n",
        "comletewords.to_excel(writer,'Sheet1')\n",
        "writer.save()\n",
        "downloaded = files.download(file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}